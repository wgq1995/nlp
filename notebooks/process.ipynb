{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "tqdm.pandas()\n",
    "\n",
    "train_path = '../data/train.csv'\n",
    "test_path = '../data/test.csv'\n",
    "embedding_path = '../data/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "train_df['question_text'] = train_df['question_text'].str.lower()\n",
    "test_df = pd.read_csv(test_path)\n",
    "test_df['question_text'] = test_df['question_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:04<00:00, 263042.38it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = train_df['question_text'].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(sentences):\n",
    "    word_count = {}\n",
    "    for sentence in tqdm(sentences):\n",
    "        for word in sentence:\n",
    "            if word not in word_count:\n",
    "                word_count[word] = 1\n",
    "            else:\n",
    "                word_count[word] += 1\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:04<00:00, 319294.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'how': 287779, 'did': 41109, 'quebec': 102, 'nationalists': 105, 'see': 9085}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_count1 = get_word_count(sentences)\n",
    "print({k: word_count1[k] for k in list(word_count1)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2196017/2196017 [01:28<00:00, 24813.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196016 85.67989299999999\n"
     ]
    }
   ],
   "source": [
    "time1 = time.clock()\n",
    "embeddings_index = {}\n",
    "embeddings_set = []\n",
    "with open(embedding_path) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        values = line.split(' ') # 要用split(' '),不能用split()\n",
    "        word = values[0]\n",
    "        #vector = np.asarray(values[1:], dtype='float32')\n",
    "        #embeddings_index[word] = vector\n",
    "        embeddings_set.append(word)\n",
    "embeddings_set = set(embeddings_set)\n",
    "print(len(embeddings_set), time.clock() - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage(word_count1, embeddings_index):\n",
    "    coverage_word = 0\n",
    "    coverage_word_count = 0\n",
    "    uncoverage = []\n",
    "    for key1 in tqdm(word_count1):\n",
    "        if key1 in embeddings_index:\n",
    "            coverage_word += 1\n",
    "            coverage_word_count += word_count1[key1]\n",
    "        else:\n",
    "            uncoverage.append([key1, word_count1[key1]])\n",
    "    uncoverage.sort(key=lambda x: x[1], reverse=True)\n",
    "    return coverage_word, coverage_word_count, uncoverage\n",
    "\n",
    "coverage_word, coverage_word_count, uncoverage = get_coverage(word_count1, embeddings_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('word coverage rate:{}\\nword count coverage rate:{}'.format(coverage_word / len(word_count1), coverage_word_count / sum(word_count1.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['India?', 16384],\n",
       " ['it?', 12900],\n",
       " [\"What's\", 12425],\n",
       " ['do?', 8753],\n",
       " ['life?', 7753],\n",
       " ['you?', 6295],\n",
       " ['me?', 6202],\n",
       " ['them?', 6140],\n",
       " ['time?', 5716],\n",
       " ['world?', 5386]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncoverage[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:42<00:00, 30937.49it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df['question_text'] = train_df['question_text'].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [02:58<00:00, 7307.51it/s]  \n",
      "100%|██████████| 1306122/1306122 [00:04<00:00, 278186.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'How': 263281, 'did': 34080, 'Quebec': 161, 'nationalists': 131, 'see': 9564}\n"
     ]
    }
   ],
   "source": [
    "sentences = train_df['question_text'].progress_apply(lambda x: x.split())\n",
    "word_count1 = get_word_count(sentences)\n",
    "print({k: word_count1[k] for k in list(word_count1)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239137/239137 [00:02<00:00, 102737.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word coverage rate:0.7496623274524645\n",
      "word count coverage rate:0.9958335729525793\n"
     ]
    }
   ],
   "source": [
    "coverage_word, coverage_word_count, uncoverage = get_coverage(word_count1, embeddings_index)\n",
    "print('word coverage rate:{}\\nword count coverage rate:{}'.format(coverage_word / len(word_count1), coverage_word_count / sum(word_count1.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Quorans', 856],\n",
       " ['Brexit', 492],\n",
       " ['cryptocurrencies', 481],\n",
       " ['Redmi', 379],\n",
       " ['C#', 231],\n",
       " ['OnePlus', 125],\n",
       " ['UCEED', 123],\n",
       " ['Blockchain', 112],\n",
       " ['GDPR', 106],\n",
       " ['demonetisation', 106]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncoverage[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Quorans', 856],\n",
       " ['Brexit', 492],\n",
       " ['cryptocurrencies', 481],\n",
       " ['Redmi', 379],\n",
       " ['C#', 231],\n",
       " ['OnePlus', 125],\n",
       " ['UCEED', 123],\n",
       " ['Blockchain', 112],\n",
       " ['GDPR', 106],\n",
       " ['demonetisation', 106],\n",
       " ['Coinbase', 105],\n",
       " ['Machedo', 99],\n",
       " ['Adityanath', 99],\n",
       " ['BNBR', 99],\n",
       " ['Boruto', 93],\n",
       " ['DCEU', 89],\n",
       " ['ethereum', 89],\n",
       " ['IIEST', 85],\n",
       " ['SJWs', 79],\n",
       " ['Qoura', 79],\n",
       " ['Upwork', 70],\n",
       " ['LNMIIT', 67],\n",
       " ['Kavalireddi', 65],\n",
       " ['Zerodha', 65],\n",
       " ['bhakts', 63],\n",
       " ['Doklam', 62],\n",
       " ['Vajiram', 59],\n",
       " ['NICMAR', 59],\n",
       " ['Unacademy', 58],\n",
       " ['MUOET', 56],\n",
       " ['chsl', 55],\n",
       " ['AlShamsi', 52],\n",
       " ['HackerRank', 52],\n",
       " ['Bhakts', 51],\n",
       " ['Awdhesh', 48],\n",
       " ['Litecoin', 48],\n",
       " ['eLitmus', 47],\n",
       " ['Jiren', 47],\n",
       " ['Cryptocurrency', 47],\n",
       " ['#1', 46],\n",
       " ['Ryzen', 45],\n",
       " ['altcoins', 45],\n",
       " ['altcoin', 45],\n",
       " ['Baahubali', 44],\n",
       " ['coinbase', 44],\n",
       " ['SRMJEE', 43],\n",
       " ['Beerus', 41],\n",
       " ['SGSITS', 40],\n",
       " ['Skripal', 40],\n",
       " ['bahubali', 38],\n",
       " ['BMSCE', 37],\n",
       " ['Zebpay', 37],\n",
       " ['Binance', 37],\n",
       " ['Gurugram', 36],\n",
       " ['Alshamsi', 36],\n",
       " ['Ravula', 36],\n",
       " ['What\\u200b', 36],\n",
       " ['BIPC', 35],\n",
       " ['upwork', 35],\n",
       " ['c#', 35],\n",
       " ['Golang', 35],\n",
       " ['SRMJEEE', 35],\n",
       " ['josaa', 35],\n",
       " ['Swachh', 34],\n",
       " ['litecoin', 34],\n",
       " ['OBOR', 33],\n",
       " ['MHCET', 33],\n",
       " ['Truecaller', 33],\n",
       " ['clickbait', 32],\n",
       " ['TensorFlow', 30],\n",
       " ['iisc', 30],\n",
       " ['Chromecast', 30],\n",
       " ['#MeToo', 30],\n",
       " ['adhaar', 29],\n",
       " ['Adhaar', 29],\n",
       " ['PESSAT', 29],\n",
       " ['USICT', 29],\n",
       " ['demonitisation', 28],\n",
       " ['Koinex', 28],\n",
       " ['Patreon', 28],\n",
       " ['microservices', 27],\n",
       " ['Whst', 27],\n",
       " ['unacademy', 27],\n",
       " ['IISERs', 26],\n",
       " ['hyperloop', 26],\n",
       " ['Demonetization', 25],\n",
       " ['fortnite', 25],\n",
       " ['Byju', 25],\n",
       " ['Bittrex', 25],\n",
       " ['ReactJS', 25],\n",
       " ['UPSE', 25],\n",
       " ['Tensorflow', 24],\n",
       " ['brexit', 24],\n",
       " ['Trumpcare', 24],\n",
       " ['Zamasu', 24],\n",
       " ['Irodov', 24],\n",
       " ['LBSNAA', 24],\n",
       " ['FTRE', 24],\n",
       " ['Codeforces', 23],\n",
       " ['NLUs', 23]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncoverage[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
